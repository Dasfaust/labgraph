# PoseVis

PoseVis is a multi-camera streaming and visualization framework built upon LabGraph. PoseVis was built with modularity in mind and can be extended to many downstream applications relatively easily through its extension system and logging support.

## Concepts

### Overview

The `PoseVis` graph is initialized using the `DynamicGraph` class, with up to 4 video streams, provided by `CameraStream`. Each `CameraStream` instance initializes enabled extensions (`PoseVisExtension` class). Image data is processed within each `CameraStream` process via a `FrameProcessor` object that handles extension execution. Extensions provide an overlay image that is combined with the original frame, and the data used to generate the overlay. The original and overlay images are packaged into a `ProcessedVideoFrame` message, and sent to the `Display` node for real-time visual feedback.

Data generated by extensions used to create the overlays is serialized to JSON and sent via the `CombinedExtensionResult` message from `CameraStream`. JSON serialization is done for simplicity, as data structures from MediaPipe vary, and miss utilities such as having a `__dict__` attribute.

The logger will log both `ProcessedVideoFrame` and `CombinedExtensionResult` messages for inspection or future usage.

## Usage

## Reading Logs

## To-do

### Testing

A testing solution needs to be implemented, this is a regression from the previous proposal for this pull request.

### Other MediaPipe Solutions

Hand tracking is currently included, with other solutions on the way. MediaPipe Python supports hand tracking, pose tracking, and face mesh tracking. These solutions can be combined into the [holistic](https://google.github.io/mediapipe/solutions/holistic.html) graph. The plan is to implement them seperately along with the holistic solution for modularity.

Other MediaPipe solutions will require C++ interop.

## Other Thoughts

### MediaPipe Performance

Currently, the hand tracking (and subsequent other) MediaPipe extensions run their neural networks on the CPU. A significant performance uplift could be achieved by running GPU-enabled MediaPipe graphs. It seems that MediaPipe's python wrapper does not have GPU capabilities: see [this issue](https://github.com/google/mediapipe/issues/3106). We could use C++ interop to achieve this.

### n-Stream Support

Pose Vis is hard coded to support 4 streams simultaneously. This limitation could be avoided with a method to change node metadata (inputs and outputs) before graph startup. This idea has proven tricky to implement due to the multi-process nature of LabGraph, but it should be possible.