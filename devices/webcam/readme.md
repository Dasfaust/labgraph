# PoseVis

PoseVis is a multi-camera streaming and visualization framework built upon LabGraph. PoseVis was built with modularity in mind and can be extended to many downstream applications relatively easily through its extension system and logging support.

## Concepts

### Overview

The `PoseVis` graph is initialized using the `DynamicGraph` class, with up to 4 video streams, provided by `CameraStream`. Each `CameraStream` instance initializes enabled extensions (`PoseVisExtension` class). Image data is processed within each `CameraStream` process via a `FrameProcessor` object that handles extension execution. Extensions provide an overlay image that is combined with the original frame, and the data used to generate the overlay. The original and overlay images are packaged into a `ProcessedVideoFrame` message, and sent to the `Display` node for real-time visual feedback.

Data generated by extensions used to create the overlays is combined into a dictionary containing the extension name and whatever data it produced. This is sent via the `CombinedExtensionResult` message from `CameraStream`.

The logger will log either `ProcessedVideoFrame` or `CombinedExtensionResult` messages (or both, based on command line arguments) for inspection or future usage.

## Usage

Requires Python 3.8 or later

Make sure to install:

```
cd devices/webcam
python setup.py install
```

### Command Line

Check usage details:

```
(.venv) python -m pose_vis.pose_vis --help               
usage: pose_vis.py [-h] [--device-ids [DEVICE_IDS ...]] [--replay REPLAY] [--replay-overlays] [--target-display-framerate [TARGET_DISPLAY_FRAMERATE]] [--device-resolutions [DEVICE_RESOLUTIONS ...]]
                   [--log-images] [--log-poses] [--log-dir [LOG_DIR]] [--log-name LOG_NAME] [--hands] [--face]

optional arguments:
  -h, --help            show this help message and exit
  --device-ids [DEVICE_IDS ...]
                        which device ids to stream
  --replay REPLAY       replay a log file (default: none)
  --replay-overlays     show previously generated overlays during replay (default: false)
  --replay-extensions   stream previously generated extension data during replay (default: false)
  --target-display-framerate [TARGET_DISPLAY_FRAMERATE]
                        specify update rate for video stream presentation; seperate from stream framerate (default: 60)
  --device-resolutions [DEVICE_RESOLUTIONS ...]
                        specify resolution/framerate per device; format is <device_id or * for all>:<W>x<H>x<FPS> (default *:1280x720x30)
  --log-images          enable image logging (default: false)
  --log-poses           enable pose data logging (default: false)
  --log-dir [LOG_DIR]   set log directory (default: ../logs)
  --log-name LOG_NAME   set log name (default: random)
  --hands               enable the hand tracking extension
  --face                enable the face detection extention
```

### As a Module

See [this Jupyter Notebook example](https://github.com/Dasfaust/labgraph/blob/pose_vis/devices/webcam/logging_example.ipynb) for PoseVis usage as a module.

## Reading Logs (HDF5)

For an example of logging output, check [this Jupyter Notebook example](https://github.com/Dasfaust/labgraph/blob/pose_vis/devices/webcam/logging_example.ipynb).

## To-do

### Testing

A testing solution needs to be implemented, this is a regression from the previous proposal for this pull request.

### VRS Support

VRS support for logging needs to be added.

### Other MediaPipe Solutions

Hand tracking is currently included, with other solutions on the way. MediaPipe Python supports hand tracking, pose tracking, and face mesh tracking. These solutions can be combined into the [holistic](https://google.github.io/mediapipe/solutions/holistic.html) graph. The plan is to implement them seperately along with the holistic solution for modularity.

Other MediaPipe solutions will require C++ interop.

## Other Thoughts

### MediaPipe Performance

Currently, the hand tracking (and subsequent other) MediaPipe extensions run their neural networks on the CPU. A significant performance uplift could be achieved by running GPU-enabled MediaPipe graphs. It seems that MediaPipe's Python wrapper does not have GPU capabilities: see [this issue](https://github.com/google/mediapipe/issues/3106). We could use C++ interop to achieve this.

### n-Stream Support

Pose Vis is hard coded to support 4 streams simultaneously. This limitation could be avoided with a method to change node metadata (inputs and outputs) before graph startup. This idea has proven tricky to implement due to the multi-process nature of LabGraph, but it should be possible.

### Multi-media Support

CV2 can be used to import a wide variety of media: videos, gifs, and image collections. We could create more stream types to support this.